{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ff9ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c conda-forge conllu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d24cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "import os\n",
    "from estnltk import Text\n",
    "from estnltk.taggers.syntax.stanza_tagger.stanza_tagger import StanzaSyntaxTagger\n",
    "from estnltk.converters.conll_exporter import  sentence_to_conll\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfd0644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \".../estnltk-version_1.6/estnltk/taggers/syntax/stanza_tagger/stanza_resources\"\n",
    "model_path = '/Users/rabauti/stanza-models/stanza_recources'\n",
    "input_type=\"morph_extended\"\n",
    "#stanza_tagger = StanzaSyntaxTagger(input_type=input_type, input_morph_layer=input_type, resources_path=model_path)\n",
    "stanza_tagger = StanzaSyntaxTagger(input_type=input_type, input_morph_layer=input_type, add_parent_and_children=True, resources_path=model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8e5300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "\n",
    "class graphFunctions:\n",
    "    \n",
    "    # tipu leidmine atribuudi väärtuse järgi\n",
    "    def get_nodes_by_attributes(G,  attrname, attrvalue ):\n",
    "        nodes = defaultdict(list)\n",
    "        {nodes[v].append(k) for k, v in nx.get_node_attributes(G,attrname).items()}\n",
    "        if attrvalue in nodes:\n",
    "            return dict(nodes)[attrvalue]\n",
    "        return []\n",
    "\n",
    "    # graafi joonistamine \n",
    "    # tipp - lemma\n",
    "    # serv - deprel\n",
    "    \n",
    "    #TODO params to **kwargs\n",
    "    def drawGraph(G, title=None, filename=None, highlight=[]):\n",
    "        \n",
    "        # soovitud tipud punaseks\n",
    "        color_map = ['red' if node in highlight else 'lightskyblue' for node in G]\n",
    "        \n",
    "        # joonise suurus, et enamik puudest ära mahuks\n",
    "        plt.rcParams[\"figure.figsize\"] = (18.5, 10.5)\n",
    "        \n",
    "        #pealkiri\n",
    "        if title:\n",
    "            title = (\"\\n\".join(wrap( title, 120)))\n",
    "            plt.title(title)\n",
    "        \n",
    "        pos = graphviz_layout(G, prog='dot')\n",
    "        labels = nx.get_node_attributes(G, 'lemma')\n",
    "        nx.draw(G, pos, cmap = plt.get_cmap('jet'),labels=labels, with_labels=True, node_color=color_map)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'deprel')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "        \n",
    "        #kui failinimi, siis salvestame faili\n",
    "        #kui pole, siis joonistame väljundisse\n",
    "        if filename:\n",
    "            plt.savefig(f'{filename}.png', dpi=100)\n",
    "        else:\n",
    "            plt.show()\n",
    "        plt.clf()\n",
    "    \n",
    "    # conllu lause objektist graafi tegemine\n",
    "    def make_graph_conllu(sentence):\n",
    "        G = nx.DiGraph()\n",
    "        for data in sentence:\n",
    "            if isinstance(data['id'], int):\n",
    "                #paneme graafi kokku\n",
    "                G.add_node(data['id'], id=data['id'], lemma=data['lemma'], pos=data['upostag'], deprel=data['deprel'], form=data['form'])\n",
    "                G.add_edge(data['id'] - data['id'] + data['head'], data['id'], deprel = data['deprel'])\n",
    "        return G\n",
    "    \n",
    "    # stanza stanza_syntax objektist graafi tegemine\n",
    "    def make_graph_stanza(sentence):\n",
    "        G = nx.DiGraph()\n",
    "        for data in sentence:\n",
    "            #print (data)\n",
    "            if isinstance(data['id'], int):\n",
    "                #paneme graafi kokku\n",
    "                G.add_node(data['id'], id=data['id'], lemma=data['lemma'], pos=data['upostag'], deprel=data['deprel'], form=data.text)\n",
    "                G.add_edge(data['id'] - data['id'] + data['head'], data['id'], deprel = data['deprel'])\n",
    "        return G\n",
    "\n",
    "    # lyhim tee graafi tippude vahel ning nn reversed kaartega graafist sama\n",
    "    def get_shortest_paths(G):\n",
    "\n",
    "        # lyhim tee tippude vahel\n",
    "        path = nx.all_pairs_shortest_path_length(G)\n",
    "        path_reversed = nx.all_pairs_shortest_path_length(G.reverse())\n",
    "        # kauguste maatriksid\n",
    "        dpath = {x[0]:x[1] for x in path}\n",
    "        dpath_reversed = {x[0]:x[1] for x in path}\n",
    "        return {'dict': path,  'dict_reversed': path_reversed, 'matrix': dpath, 'matrix_reversed': dpath_reversed}\n",
    "\n",
    "    #tagastab array-na syntaksipuu graafi propreteid, tippu 0 ignoreerib\n",
    "    def get_prop(graph, property_name):\n",
    "        return [graph.nodes[node][property_name] for node in sorted([node for node in graph.nodes]) if node]\n",
    "    \n",
    "    #leiab, millised tipud suuremast graafist1 on puudu graafis2\n",
    "    def get_nodes_diff(graph1, graph2):\n",
    "        return [ node for node in graph1 if not node in graph2 ]\n",
    "\n",
    "#sisendiks on lausepuu nn tabeli kujul connlu sentence\n",
    "# teeme sellest graafi connections abil\n",
    "# siis kustutame soovitud depreli haru ja paneme lause tagasi kokku\n",
    "import networkx as nx\n",
    "\n",
    "#tekst on tokeniseeritud, võib tühikuga otsida küll\n",
    "def is_enne_kui_examples(text):\n",
    "    sent = ' ' + text.lower() + ' '\n",
    "    kui = [' rohkem kui ', ' vähem kui ', ' samapalju kui ', ' enam kui ']\n",
    "    for k in kui:\n",
    "        if k in sent:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def remove_deprel_ennekui(inputG, rem_deprel):\n",
    "    \n",
    "    #eemaldame ainult siis, kui advmod lemma on [rohkem, vähem, samapalju, enam]\n",
    "    # ja kui sellele s]nale vahetult järgnes lemma \"kui\"\n",
    "    \n",
    "    G = inputG.copy()\n",
    "    #originaallause graaf\n",
    "    G_original = inputG.copy() \n",
    "   \n",
    "    #tipud eemaldatava depreliga\n",
    "    rem_deprel_nodes = graphFunctions.get_nodes_by_attributes(G, 'deprel', rem_deprel)\n",
    "    \n",
    "    # lemmade nimekiri praegu ei kasuta, vb tuleb t2psustada, mis lemmat eemaldame\n",
    "    # näiteks, antud juhul võibolla tahame eemaldada ainult seda advmodi, kus on kui-le järgnev sõna või kui\n",
    "    #lemmas = nx.get_node_attributes(G, \"lemma\")\n",
    "    \n",
    "    #eemaldame tipud, mis on otsitava deprel'iga\n",
    "    for n in rem_deprel_nodes:\n",
    "        \n",
    "        #lisatingumus enne_kui jaoks\n",
    "        if G.nodes[n]['lemma'] in ['rohkem', 'vähem', 'samapalju', 'enam']:\n",
    "            if n+1 in G.nodes and G.nodes[n+1]['lemma'] == 'kui':\n",
    "                G.remove_node(n)\n",
    "    \n",
    "    # lyhim tee tippude vahel ja kauguste maatriksid\n",
    "    paths = graphFunctions.get_shortest_paths(G)\n",
    "    #paths['matrix'] on dictionary lyhima kaugusega seotud tippudega\n",
    "    #print ('dpath', dpath)\n",
    "    \n",
    "    #eemaldame kõik tipud, mis pole enam sidusad\n",
    "    #eeldame siin praegu, et verbi ei eemaldata\n",
    "    nodes = [node for node in G.nodes]\n",
    "    for node in nodes:\n",
    "        if node>0 and not node in paths['matrix'][0]:\n",
    "            G.remove_node(node)\n",
    "    \n",
    "    \n",
    "    deprels = [G.nodes[node]['deprel'] if node in G.nodes else '_' for node in sorted([node for node in G_original.nodes]) if node ]\n",
    "    \n",
    "    return G\n",
    "\n",
    "\n",
    "        \n",
    "def analyze_as_graph(text, stanza_tagger):\n",
    "    #uus analüüs\n",
    "    short_sent_txt = Text(text)\n",
    "    short_sent_txt.analyse('all')\n",
    "    stanza_tagger.tag(short_sent_txt)\n",
    "    new_graph = graphFunctions.make_graph_stanza(short_sent_txt.stanza_syntax)\n",
    "    return new_graph\n",
    "\n",
    "#add blanks at position of indexes instead of removed words\n",
    "def add_blanks(a, indexes, blank='_'):\n",
    "    array=a.copy()\n",
    "    for ind in sorted(indexes):   \n",
    "        array.insert(ind-1, blank)\n",
    "       \n",
    "    return array\n",
    "\n",
    "def remove_removed(a, indexes):\n",
    "    #print (array, indexes)\n",
    "    array=a.copy()\n",
    "    for ind in reversed(sorted(indexes)):\n",
    "        array.pop(ind-1)\n",
    "    return array\n",
    "\n",
    "\n",
    "def is_equal(arr1, arr2):\n",
    "    if not len(arr1) == len(arr2):\n",
    "        return False\n",
    "    for i in range(len(arr1)):\n",
    "        if not arr1[i] == arr2[i]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "965c203a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EDTtreex/Testtreex', 'aja_pm20000218_osa_4_ud28.enhanced.treex.conllu'),\n",
       " ('EDTtreex/Testtreex', 'tea_dr8020_ud28.enhanced.treex.conllu'),\n",
       " ('EDTtreex/Testtreex', 'aja_pm20000218_osa_3_ud28.enhanced.treex.conllu')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make list of files\n",
    "from io import open\n",
    "from conllu import parse\n",
    "\n",
    "\n",
    "CONLLU_ROOT='/Users/rabauti/repos/tu/EstUD/vers2_8_enhanced/'\n",
    "connlu_files = []\n",
    "for path, subdirs, files in os.walk(CONLLU_ROOT):\n",
    "    for name in files:\n",
    "        if name.endswith('.conllu'):\n",
    "            connlu_files.append((path.replace(CONLLU_ROOT, ''), name))\n",
    "connlu_files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7de37bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kokku faile:  117\n",
      "Kokku lauseid: 32644\n",
      "\tLauseid, kus oli nn \"enne-kui\" konstruktsioon: 130\n",
      "\t\t Polnud advmod tippu eemaldamiseks: 35\n",
      "\t\t Süntaks konserveerus: 23\n",
      "\t\t Süntaks ei konserveerunud: 72\n",
      "CPU times: user 1min 22s, sys: 9.15 s, total: 1min 31s\n",
      "Wall time: 2min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1332x756 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import csv\n",
    "\n",
    "from pathlib import Path\n",
    "Path(\"./results\").mkdir(parents=True, exist_ok=True) \n",
    "Path(\"./results/imgtrees\").mkdir(parents=True, exist_ok=True) \n",
    "Path(\"./results/imgtrees/changed\").mkdir(parents=True, exist_ok=True) \n",
    "Path(\"./results/imgtrees/conserved\").mkdir(parents=True, exist_ok=True) \n",
    "Path(\"./results/imgtrees/constant\").mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "\n",
    "stats = {}\n",
    "stats['faile_kokku'] = len(connlu_files)\n",
    "stats['lauseid_kokku'] = 0\n",
    "stats['ennekui_lauseid_kokku'] = 0\n",
    "\n",
    "stats['ennekui_lauseid_muutunud'] = 0\n",
    "stats['ennekui_lauseid_konserveerunud'] = 0\n",
    "stats['ennekui_lauseid_puudub_advmod'] = 0\n",
    "\n",
    "\n",
    "outputfile_changed = f'results/UD_ennekui_changed.tsv' \n",
    "outputfile_conserved = f'results/UD_ennekui_conserved.tsv'\n",
    "outputfile_constant = f'results/UD_ennekui_constant.tsv' \n",
    "\n",
    "outChanged = open(outputfile_changed, 'w', encoding='utf-8')\n",
    "outConserved = open(outputfile_conserved, 'w', encoding='utf-8')\n",
    "outConstant = open(outputfile_constant, 'w', encoding='utf-8')\n",
    "\n",
    "# create the csv writer\n",
    "wChanged = csv.writer(outChanged, delimiter='\\t')\n",
    "wConserved = csv.writer(outConserved, delimiter='\\t')\n",
    "wConstant = csv.writer(outConstant, delimiter='\\t')\n",
    "\n",
    "\n",
    "wConserved.writerow(('FILE','SENTENCE_ID', 'TYPE', 'TEXT', 'DEPRELS',),)\n",
    "wChanged.writerow(('FILE','SENTENCE_ID', 'TYPE', 'TEXT', 'DEPRELS',),)\n",
    "wConstant.writerow(('FILE','SENTENCE_ID', 'TYPE', 'TEXT', 'DEPRELS',),)\n",
    "\n",
    "emptyrow = ('', '', '', '', '', )\n",
    "\n",
    "deprel = 'advmod'\n",
    "\n",
    "for directory, file  in connlu_files:\n",
    "    \n",
    "    filepath = f\"{directory}/{file}\"\n",
    "    data_file = open(f\"{CONLLU_ROOT}{directory}/{file}\", \"r\", encoding=\"utf-8\")\n",
    "\n",
    "    data = data_file.read()\n",
    "    sentences = parse(data)\n",
    "    \n",
    "    #cols  sent id type  sentence deprels\n",
    "    changed = []\n",
    "    conserved = []\n",
    "    for sent in sentences:\n",
    "        nodes_diff = []\n",
    "        stats['lauseid_kokku'] +=1\n",
    "        \n",
    "        row = []\n",
    "        originaltext = sent.metadata['text']\n",
    "        sent_id = sent.metadata['sent_id']\n",
    "        global_sent_id = f'{directory}/{file}_{sent_id}'.replace('/', '__')\n",
    "        \n",
    "        #print ('O:', originaltext)\n",
    "        g_orig = graphFunctions.make_graph_conllu(sent)\n",
    "        deprel_origin = graphFunctions.get_prop(g_orig, 'deprel')\n",
    "        \n",
    "        \n",
    "        #v6tame siit, sest originaalkuju on tokeniseerimata\n",
    "        original_text = \" \".join(graphFunctions.get_prop(g_orig, 'form'))\n",
    "        \n",
    "        if  not is_enne_kui_examples(original_text): \n",
    "            #print ('NOT', originaltext)\n",
    "            continue\n",
    "        stats['ennekui_lauseid_kokku'] +=1\n",
    "        \n",
    "        #print ('-----')\n",
    "\n",
    "       \n",
    "        g_short = remove_deprel_ennekui(g_orig, deprel)\n",
    "        short_text = \" \".join(graphFunctions.get_prop(g_short, 'form'))\n",
    "        \n",
    "        #esimene täht suureks\n",
    "        \n",
    "\n",
    "        #kui tekst ei muutunud, jätkame\n",
    "        if original_text == short_text: \n",
    "            \n",
    "            row1 = [filepath\\\n",
    "                , sent_id\\\n",
    "                , 'O'\\\n",
    "                , original_text\\\n",
    "                , \" \".join(deprel_origin)]\n",
    "            wConstant.writerow(row1)\n",
    "            wConstant.writerow(emptyrow)\n",
    "            stats['ennekui_lauseid_puudub_advmod'] +=1\n",
    "            \n",
    "            graphFunctions.drawGraph(g_orig, \" \".join(graphFunctions.get_prop(g_orig, 'form')), f'results/imgtrees/constant/{global_sent_id}_original', nodes_diff)\n",
    "       \n",
    "            continue\n",
    "\n",
    "        \n",
    "\n",
    "        #kui tekst muutus, siis:\n",
    "        #teeme uue lauseanalüüsi Stanzaga\n",
    "        #teisendame graafiks\n",
    "        #graafist küsime deprelid\n",
    "\n",
    "        nodes_diff = graphFunctions.get_nodes_diff(g_orig, g_short)\n",
    "        if 1 in nodes_diff:\n",
    "            short_text = short_text[0].upper() + short_text[1:]\n",
    "     \n",
    "        #uus analüüs\n",
    "        new_graph = analyze_as_graph(short_text, stanza_tagger)\n",
    "\n",
    "        #peame teadma, mis nr sõnad kadusid, et saaks võrrelda??\n",
    "        \n",
    "        \n",
    "        \n",
    "        deprel_short = graphFunctions.get_prop(new_graph, 'deprel')\n",
    "        deprel_with_blanks = add_blanks(deprel_short,nodes_diff)\n",
    "        original_removed = remove_removed(deprel_origin, nodes_diff)\n",
    "        #graphFunctions.drawGraph(g_short, \" \".join(get_prop(g_short, 'form')), f'imgtrees/{global_sent_id}_removed')\n",
    " \n",
    "        row1 = [filepath\\\n",
    "                , sent_id\\\n",
    "                , 'O'\\\n",
    "                , original_text\\\n",
    "                , \" \".join(deprel_origin)]\n",
    "    \n",
    "        row2 = [filepath\\\n",
    "                , sent_id \\\n",
    "                , 'S'\\\n",
    "                , short_text\\\n",
    "                , \" \".join(deprel_with_blanks)]\n",
    "    \n",
    "        conserved = is_equal(deprel_short, original_removed)\n",
    "        if conserved:\n",
    "            wConserved.writerow(row1)\n",
    "            wConserved.writerow(row2)\n",
    "            wConserved.writerow(emptyrow)\n",
    "            stats['ennekui_lauseid_konserveerunud'] +=1\n",
    "            graphFunctions.drawGraph(g_orig, \" \".join(graphFunctions.get_prop(g_orig, 'form')), f'results/imgtrees/conserved/{global_sent_id}_original', nodes_diff)\n",
    "       \n",
    "\n",
    "            \n",
    "\n",
    "        else:\n",
    "            wChanged.writerow(row1)\n",
    "            wChanged.writerow(row2)\n",
    "            wChanged.writerow(emptyrow)\n",
    "            graphFunctions.drawGraph(g_orig, \" \".join(graphFunctions.get_prop(g_orig, 'form')), f'results/imgtrees/changed/{global_sent_id}_original', nodes_diff)\n",
    "            graphFunctions.drawGraph(new_graph, \" \".join(graphFunctions.get_prop(new_graph, 'form')), f'results/imgtrees/changed/{global_sent_id}_post')\n",
    "            stats['ennekui_lauseid_muutunud'] += 1\n",
    "            \n",
    "outChanged.close()\n",
    "outConserved.close()\n",
    "outConstant.close()\n",
    "    \n",
    "\n",
    "print (f\"Kokku faile:  {stats['faile_kokku']}\")\n",
    "print (f\"Kokku lauseid: {stats['lauseid_kokku']}\")\n",
    "\n",
    "print (f\"\\tLauseid, kus oli nn \\\"enne-kui\\\" konstruktsioon: {stats['ennekui_lauseid_kokku']}\")\n",
    "\n",
    "print (f\"\\t\\t Polnud advmod tippu eemaldamiseks: {stats['ennekui_lauseid_puudub_advmod']}\")\n",
    "\n",
    "print (f\"\\t\\t Süntaks konserveerus: {stats['ennekui_lauseid_konserveerunud']}\")\n",
    "\n",
    "print (f\"\\t\\t Süntaks ei konserveerunud: {stats['ennekui_lauseid_muutunud']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84f41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
